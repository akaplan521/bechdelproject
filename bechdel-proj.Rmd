---
title: "Bechdel Project Draft"
output: html_document
date: "2024-03-07"
authors: "Alexa Kaplan, Alec Beland, Catherine Crowell, Carolyn Kelly"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center",
                      message = F,
                      warning = F)

#load packages we will need
install.packages("dplyr", repos = "http://cran.us.r-project.org")
pacman::p_load(tidyverse, skimr, rpart, class, caret, rpart.plot)

#we can also change default themes here if necessary

#read in the data file here!!!

bechdel <- read_csv("bechdel2.csv")

```

## I. Introduction


The Bechdel Test assesses female representation in film. To pass, the film must show two women who talk to each other about something other than men. The data we are working with is the "Movies Bechdel Test" data set from the miscellaneous data sets provided on Brightspace. It contains data on 1,793 films ranging from the years 1970 to 2013, including their 

1. **imdbId**: IMDB id number
2. **year**: Year released
3. **Decade**: Decade released 
4. **title.y**: Title of the film
5. **Btest**: Result of the bechdel test:
6. **Btest5**: on a scale of 1 to 5: A score of 1 passes the test; a score of 2 is "dubious" as it is unclear whether the dialogue between the two women is sufficient to pass; a film with a 3 includes women who talk to each other exclusively about men; a 4 has women who do not talk to each other; and, finally, a 5 has no female characters.
7. **budget13**: The film's budget
8. **domgross13**: Domestic grossing
9. **intgross13**: International grossing
10. **domprofit13**: Domestic profit
11. **intprofit13**: International Profit
12. **averating**: The average rating of the film
13. **nrating**: The number of ratings considered in **averating**

There is a potential for sampling bias in our data set, because the movies were selected if they were on the BechdelTest.com website which details 5,000 films as well as in The-Numbers.com website which includes financial data on films. The need to eliminate films that do not overlap on these two websites could lead to selection bias. Nevertheless, our sample amounts to 1,793 films out of Hollywood in the time frame of four decades which is not insignificant, and the larger the sample, the lower the bias. There should be no issue with recall or confirmation bias in our data since all measurements from profits and budget are quantitative, not qualitative, as well as the Bechdel Test itself which turns objective criteria into a numeric score.

This data is of interest because, while we like to think that gender equality and gender roles have drastically improved in the past five decades (range of this data set), we can look at the variable of female representation in film to check social progress as it has translated to Hollywood. It will be interesting to visualize how the the finances of films which pass the Bechdel test, a "bare minimum" of fair female representation, compare with the rest of the films. 

As for data cleaning, data points with missing values were removed so that results would not be skewed. 

## Data Cleaning


```{r question 1 - Introduction}
#data cleaning here described above...
bechdel_factored <- bechdel |> 
  mutate(score = case_when(Btest5 == "1 ok" ~ 1,
                           Btest5 == "2 dubious" ~ 2,
                           Btest5 == "3 men" ~ 3,
                           Btest5 == "4 notalk" ~ 4,
                           Btest5 == "5 nowomen" ~ 5)) |> 
  select(-Btest5)
  
```

## II. Data Visualizations:


```{r question 2 - Data Visualizations (barplot)}

#barplot to show scores by number of films

bechdBar <- ggplot(
    data = bechdel_factored,
    mapping = aes(x = fct_rev(factor(score)))) +
  
  geom_bar(aes(fill = factor(score)),
           color = "black") +
  
  scale_fill_manual(values = c('#81ff6e', '#ecff96', '#ffe896', '#faaf7d', '#fa3e3e')) +
  
  scale_y_continuous(expand = c(0, 0, 0.05, 0), 
                     labels = scales::label_percent()) +
  
  labs(x = "Bechdel Score", 
       y = "Number of Films",
       title = "Number of Films by Bechdel Rating") +
  
  theme_classic() +
  
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.4),
        plot.background = element_rect(fill = "lightsteelblue1"),
        panel.background = element_rect(fill = "lightsteelblue3"))

# Show graph
bechdBar

```

This bar chart shows the total count of films with each unique Bechdel test score in our data set. The highest proportion of movies have a score of one, passing the Bechdel test, with the next highest score being a 4, indicating that females are in the movie but do not speak. If added up, the count of Bechdel scores between 2-5 (do not pass) still outnumber the quantity of films that do pass the test. 


```{r question 2 - Data Visualizations (boxplot)}
# line to rating by score 
bechdByRating <-
  ggplot(
    data = bechdel_factored,
    mapping = aes(
      x = averating,
      y = fct_rev(factor(score)),
      fill = factor(score)
    )
  ) +
  
  geom_boxplot() +
  
  scale_fill_manual(values=c('#81ff6e', '#ecff96', '#ffe896', '#faaf7d', '#fa3e3e')) +
  
  theme_classic() +
  
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.4),
        plot.background = element_rect(fill = "lightsteelblue1"),
        panel.background = element_rect(fill = "lightsteelblue3")) +
  
  labs(
    x = "Average Rating (Out of 5 Stars)",
    y = "Bechdel Score (1 = Pass)",
    title = "Bechdel Score VS Average Rating"
  ) 

# show graph
bechdByRating


```

In this box plot, the average rating out of five of a given film is on the x-axis and the Bechdel score it received is on the y-axis. The highest concentrations of films have a rating of between 3 and 4 and a bechdel score of either 1 or 4. 


```{r question 2 - Data Visualizations (scatter)}
# scatter to show rating by score with lines
bechdScatter <- ggplot(
  data = bechdel_factored,
  mapping = aes(
    x = averating,
    y = budget13,
    color = factor(score)
  )
) +
  
  geom_point() +
  
  geom_smooth(
    method = loess,
    formula = y~x,
    se = F
  ) +
  
  labs(
    x = "Average Rating",
    y = "Budget",
    title = "Correlation of Budget with Average Rating",
    color = "Score"
  ) +
  
  scale_color_manual(values=c('#81ff6e', '#ecff96', '#ffe896', '#faaf7d', '#fa3e3e')) +
  
  theme_classic() +
  
  theme(
    plot.background = element_rect(fill = "lightsteelblue1"),
    panel.background = element_rect(fill = "lightsteelblue3"),
    legend.background = element_rect(fill = "lightsteelblue3"))

# show graph
bechdScatter

```

Each point on this scatterplot is positioned by its average rating on the x-axis and the budget of the film on the y-axis. The color of each point, indicated in the key, represents a different Bechdel score rating, with a trend line for each to show the pattern of how its rating and budget relate. 

```{r question 2 - Data Visualizations (side-by-side bar)}
# side-by-side bars to show domestic vs international profit
# data modification
bechdel_profit_type <- bechdel_factored |> 
  select(Btest, domgross13, intgross13) |> 
  na.omit() |> 
  pivot_longer(
    cols = c(domgross13:intgross13),
    names_to = "profitType", 
    values_to = "value"
  )

bechdel_profit_type$Btest <- as.factor(bechdel_profit_type$Btest)

# calculate mean
means <- bechdel_profit_type |> 
  group_by(Btest, profitType)  |> 
  summarise(mean_value = mean(value))


# graph
bech_stacked_bar <- ggplot(
  data = means,
  mapping = aes(
    x = profitType,
    y = mean_value,
    fill = Btest
  )
) +
  geom_bar(
    aes(y = mean_value),
    color = "black",
    stat = "identity",
    position = "dodge2"
  ) +
  
  # Remove space under graph
  scale_y_continuous(
    expand = c(0, 0, 0.05, 0)
  ) +
  
  # add labels
  labs(
    x = "Profit Type",
    y = "Mean Gross Value (in Thousands)",
    fill = "Bechdel Test Result",
    title = "Outcome of Bechdel Test Across Domestic and International Gross"
    ) +
  
  # change colors
  scale_fill_manual(values=c('#fa3e3e', '#81ff6e')) +
  
  # change x-axis 
  scale_x_discrete(labels = c("domgross13" = "Domestic", "intgross13" = "International"))

bech_stacked_bar

```

This graph compares how films of each of the Bechdel test scores fared in international and domestic profit. This indicates if there was any difference is international success that could be due to female representation or lack thereof. 

```{r question 2 - Data Visualizations (stacked bar)}
# compare bechdel ratings by decade
bechdel_factored$Decade <- as.factor(bechdel_factored$Decade)
bechdel_factored$score <- as.factor(bechdel_factored$score)

bech_by_decade <- ggplot(bechdel_factored,
                         mapping = aes(x = Decade,
                         fill = score))    +
    
  geom_bar(position = "fill")    +
  # Adding a title, removing the labels for y and fill
  labs(x = "Decade", 
       y = "Percentage of Films", 
       fill = "Bechdel Score", 
       title = "Bechdel Ratings For Different Decades")    +
  # Changing the tickmarks to percentages and removing the buffer space
  scale_y_continuous(expand = c(0, 0, 0.05, 0), 
                     labels = scales::label_percent())    +
  scale_fill_manual(values=c('#81ff6e', '#ecff96', '#ffe896', '#faaf7d', '#fa3e3e')) +

  # Changing the theme to theme_classic()
  theme_classic() +
  # Centering the title
  theme(plot.title = element_text(hjust = 0.8),
        plot.background = element_rect(fill = "lightsteelblue1"),
        panel.background = element_rect(fill = "lightsteelblue3"),
        legend.background = element_rect(fill = "lightsteelblue3"))

# show graph
bech_by_decade
```

This stacked bar chart segments the films in our data by decade on the x-axis and the the data within each bar shows the percentage of films in our data set that accounted for each score 1-5 of the Bechdel test. Passing scores appear to increase as the decades pass which is a positive sign, although it is consistent that the majority of films throughout each of the five decades do not pass this simple test. 

## III: Machine Learning Methods

#kNN Classification
```{r}

bechdel_k <- bechdel |> 
  select(-imdbId, -Decade, -title.y, -Btest5, -domprofit13, -intprofit13) |> 
  na.omit() |>
  relocate(Btest)
# Set up functions for data modification

# Normalize function:
normalize <- function(x) {
  norm_x <- (x - min(x)) / (max(x) - min(x))
  return(norm_x)
}

# Standardize function:
standardize <- function(x) {
  standard_x <- (x - mean(x))/(sd(x))
  return(standard_x)
}

# Modify the data 

# Normalize the data
bech_norm <-
  bechdel_k |> 
  mutate(
    across(
      .cols = -Btest,
      .fns = normalize
    )
  )

# Standardizing the data
bech_stan <-
  bechdel_k |>  
  mutate(
    across(
      .cols = -Btest,
      .fns = standardize
    )
  )

# Check the data

# Check that normalization worked for 3 variables:
bech_norm |> 
  # Changing from wide to long format
  pivot_longer(
    cols = -Btest,
    names_to = "feature"
  ) |> 
  # calculating the mean, sd, min, and max for each feature
  summarize(
    .by = feature,
    average = mean(value) |> round(digits = 2),
    standard_deviation = sd(value) |> round(digits = 2),
    p0 = min(value) |> round(digits = 2),
    p100 = max(value) |> round(digits = 2)
  )

# Check that standardization worked for 3 variables:
bech_stan |> 
  # Changing from wide to long format
  pivot_longer(
    cols = -Btest,
    names_to = "feature"
  ) |> 
  # calculating the mean, sd, min, and max for each feature
  summarize(
    .by = feature,
    average = mean(value) |> round(digits = 2),
    standard_deviation = sd(value) |> round(digits = 2),
    p0 = min(value) |> round(digits = 2),
    p100 = max(value) |> round(digits = 2)
  )
```
#Looping through K
```{r k loop}
# Keep this at the top
RNGversion("4.1.0"); set.seed(1234)

# create tibble
### CHANGE K
knn_results <-
  tibble(
    k = 5:100,
    norm_acc = rep(-1, length(k)),
    stan_acc = rep(-1, length(k))
  )

#changing response variable to factors in all dataframes
bechdel_k$Btest <- as.factor(bechdel_k$Btest)
bech_stan$Btest <- as.factor(bech_stan$Btest)
bech_norm$Btest <- as.factor(bech_norm$Btest)

# for loop to cycle through each different choice in the k column of knn_acc
for (i in 1:nrow(knn_results)) {
  # predict for norm data
  knn_norm <-
    knn.cv(
      train = bech_norm[ , -1],
      cl = bechdel_k$Btest,
      k = knn_results$k[i],
    )
  
  knn_results$norm_acc[i] <- mean(knn_norm == bechdel_k$Btest)
  
  # predict for stan data
  knn_stan <-
    knn.cv(
      train = bech_stan[ , -1],
      cl = bechdel_k$Btest,
      k = knn_results$k[i]   
    )
  
  knn_results$stan_acc[i] <- mean(knn_stan == bechdel_k$Btest)
}


# Displaying the first 10 rows
tibble(knn_results)

knn_results

```

#Graphing results of kNN classification

```{r graphing results }

# graph
knn_results |> 
  pivot_longer(
    cols =-k,
    values_to = "acc",
    names_to = "rescale"
  ) |> 
  # forming our line graph
  ggplot(
    mapping = aes(
      x = k,
      y = acc,
      color = rescale
    )
  ) +
  
  # add line
  geom_line(
    size = 1
  ) +
  
  # add labels
  labs(
    x = "Choice of k",
    y = "accuracy",
    color = "Rescale Method"
  ) +
  
  # change y-axis to percentages
  scale_y_continuous(
    labels = scales::percent_format()
  ) +
  
  # move legend
  theme(
    legend.position = c(0.8, 0.8)
  ) +
  
  # change x-axis to increments of 10
  scale_x_continuous(
    breaks = seq(10, 100, by = 10),
    labels = seq(10, max(100), by = 10)
  ) +
  
  # change legend values
  scale_color_manual(
    labels = c("Normalized", "Standardized"),
    values = c("#F8766D", "#00BFC4")
  )
  
```

```{r finding best k and method}
# display best accuracy across methods
knn_results |> 
  pivot_longer(
    cols = -k,
    names_to = "rescale_method",
    values_to = "accuracy"
  ) |> 
  slice_max(accuracy)

```
Using the graph as well as code to isolate the maximum accuracy for each value of k with both the standardized and normalized data, we can see that the best choice is to use *k = 38* and *standardized* data.
###kNN Classification

```{r confusion matrix}
# knn for best k value
bech_knn <- 
  knn(
    train = bech_stan |> dplyr::select(-Btest),
    test = bech_stan[ , -1],
    cl = bech_stan$Btest,
    k = 38
  )

# confusion matrix
confusionMatrix(
  data = bech_knn,
  reference = bechdel_k$Btest
)

```

By using kNN we imporve the accuracy from 59% (No Info Rate) to 64.62%. The   true accuracy of the model is likely to fall between 0.6179 to 0.6738 (95% CI). The p-value is 0.0001, less than the significance level of 0.05, suggests that the model's accuracy is significantly different from what would be achieved by choosing only FAIL.


##Classification Tree

```{r tree}

full_tree <-
  rpart(
    formula = Btest ~ .,
    data = bechdel_k,
    method = "class",
    # we want to use entropy to split the nodes
    parms = list(split = "information"),
    # NEXT: three arguments will fully grow the tree
    minsplit = 2,
    minbucket = 1,
    cp = -1
  )

data.frame(full_tree$cptable)

```
#Finding pruning point
```{r find pruning point}
# Use the cptable to find the best value of cp to use the prune the full tree
xcutoff <- 
  full_tree$cptable |> 
  data.frame() |> 
  # pick the row with the lowest xerror (cross-validation error)
  slice_min(xerror, n = 1) |> 
  # pick min k
  slice_min(nsplit, n = 1) |> 
  # calculate xcutoff as xerror + xstd
  mutate(
    xcutoff = xerror + xstd
  ) |> 
  # keep just the xcutoff
  pull(xcutoff)

cp_prune <-
  full_tree$cptable |> 
  data.frame() |> 
  # finding 'all' rows with xerror < xcutoff
  filter(
    xerror < xcutoff
  ) |> 
  # keeping the simplest tree (first row)
  slice(1) |> 
  # extract the cp value
  pull(CP)

c("xcutoff" = xcutoff,
  "cp" = cp_prune)
```
```{r pruned tree}
# Prune the tree
tree_pruned <-
  prune(
    tree = full_tree,
    cp = cp_prune
  )

# Then plot it:
rpart.plot(
  x = tree_pruned,
  extra = 104
)

```

The resulting pruned tree has only one node. This suggeststhat the model is significantly flawed--not suprising. Imbalanced data is a viable explanation for these issues as well as a lack of nuance and diversity in the explanatory variables and data respectively. 



###Conclusions

The average rating of the films in our data set does not appear to be related to whether or not it passes the Bechdel test. According to the box plots which compare a film’s average rating out of five to how much of the Bechdel test it achieved, any difference in median and range score is negligible. The graph visualizing how films of different Bechdel scores’ average ratings compare to their budgets would imply that this relationship is random, so the budget variable is not a reliable predictor of Bechdel score. The decade variable, however, did show some correlation with whether or not a film passed the test, showing an upward trend in the percentage of films passing the Bechdel test with just about each decade that passes. For this particular data, classification machine learning techniques are best suited for predicting class variables--in this case the result of the Bechdel test(Pass/Fail). Because our data is imbalanced in terms of classes(Pass/Fail), accuracy may not be the best measure of our kNN model because systemically predicting the majority class(Fail) would already yield better results. If we were to consider accuracy however, we would conclude that an accuracy of 64.62% is not overwhelmingly good. This could very well be attributed to the fact that the predictors included in the model may not necessarily correlate strongly with Bechdel test results. The classification tree has no leaves indicating the model is extremely over-simplified and should not be used to generalize new data. 

###Limitations and Recommendations 
The requirement that each film exist in both the Bechdel website and the website tracking film finances led to selection bias that may have impacted our results. Future endeavors to visualize patterns in films with respect to female representation should consider how to minimize bias when sourcing their data. The project could be improved by using films outside of Hollywood, independent or international productions, for example, which would offer a bigger pool of movie that pass the Bechdel test, increasing the sample so that we might be able to find a more prominent pattern in how successful the film turned out to be and why. A main limitation in our analyses was a narrow range of predictors included in the data. Including a broader range of predictors that better capture the diverse factors influencing Bechdel test results would likely improve results. The machine learning models both of them fail to capture the variability of the data. The data used in these models was unbalanced which skewed the accuracy of the kNN model to appear better than it should be. Utilizing more diverse and representative data which incorporated a broader range of predictors may have seen more accurate classification models. 


